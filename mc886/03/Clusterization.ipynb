{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterização de emails\n",
    "### André Almeida, 164047\n",
    "### Igor Torrente, 169820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Bibliotecas utilizadas ###\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from numpy import genfromtxt\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Tratamento de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizando a base `data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Database/data.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-98b044a6770e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Pegando dados do banco de dados (data.csv) ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Database/data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows)\u001b[0m\n\u001b[1;32m   1549\u001b[0m                 \u001b[0mfhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rbU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                 \u001b[0mfhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_file_openers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Database/data.csv not found."
     ]
    }
   ],
   "source": [
    "### Pegando dados do banco de dados (data.csv) ###\n",
    "database = genfromtxt('Database/data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções de pré-processamento para tratamentos alternativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFiles(path, data_size=19393):\n",
    "    data = []\n",
    "    for i in range(0, data_size):\n",
    "        with open(path + str(i) + \".txt\", 'r') as f:\n",
    "            data.append(f.read())\n",
    "    return data\n",
    "\n",
    "def getData(stopwords=False, stem=None):\n",
    "    print(\"stopwords:\", stopwords, \" stem:\", stem)\n",
    "    data_size = 19393\n",
    "    data_path = \"data/\"\n",
    "\n",
    "    if not stopwords  and stem == None:\n",
    "        return getFiles(data_path + \"no-stem/original/original\")\n",
    "\n",
    "    if stopwords and stem == None:\n",
    "        return getFiles(data_path + \"no-stem/sw/sw\")\n",
    "\n",
    "    if stem == \"lanc\" and not stopwords:\n",
    "        return getFiles(data_path + \"stem/original/lanc/lanc\")\n",
    "\n",
    "    if stem == \"lanc\" and stopwords:\n",
    "        return getFiles(data_path + \"stem/sw/lanc/lanc\")\n",
    "\n",
    "    if stem == \"porter\" and not stopwords:\n",
    "        return getFiles(data_path + \"stem/original/porter/porter\")\n",
    "\n",
    "    if stem == \"porter\" and stopwords:\n",
    "        return getFiles(data_path + \"stem/sw/porter/porter\")\n",
    "\n",
    "    if stem == \"snow\" and not stopwords:\n",
    "        return getFiles(data_path + \"stem/original/snow/snow\")\n",
    "\n",
    "    if stem == \"snow\" and stopwords:\n",
    "        return getFiles(data_path + \"stem/sw/snow/snow\")\n",
    "\n",
    "    if stem == \"wn\" and not stopwords:\n",
    "        return getFiles(data_path + \"stem/original/wn/wn\")\n",
    "\n",
    "    if stem == \"wn\" and stopwords:\n",
    "        return getFiles(data_path + \"stem/sw/wn/wn\")\n",
    "\n",
    "def printClusterTerms(km, vectorizer):\n",
    "    assigned_cluster = km.labels_\n",
    "    cluster_terms = []\n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(km.n_clusters):\n",
    "        print(\"Cluster {:>2} ({:>4} docs): \".format(i, len([x for x in km.labels_ if x == i])), end='')\n",
    "        cterms = []\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' {}'.format(terms[ind]), end='')\n",
    "            cterms.append(terms[ind])\n",
    "        cluster_terms.append(' '.join(cterms))\n",
    "        print(\"\")\n",
    "        \n",
    "def trainCustomSets(data, k):\n",
    "    global km\n",
    "    print(\"Number of clusters:\", k)\n",
    "    vectorizer = TfidfVectorizer(min_df=2, max_df = 800)\n",
    "    tdm = vectorizer.fit_transform(data)\n",
    "    km = KMeans(n_clusters=k, random_state=0, n_jobs=(-1)).fit(tdm)\n",
    "    scr = km.score(tdm)\n",
    "    print(\"scr: \", scr)\n",
    "    printClusterTerms(km, vectorizer)\n",
    "    return scr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Função que aplica PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applyPCA(perc, database):\n",
    "    pca = PCA(n_components=perc)\n",
    "    pca.fit(database)\n",
    "    pca_fit = pca.transform(database)\n",
    "\n",
    "    soma = 0\n",
    "    for i in pca.explained_variance_ratio_:\n",
    "        soma += i\n",
    "    print(\"Dados removidos/reduzidos: \", soma)\n",
    "    \n",
    "    return pca_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Soluções propostas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _A. K-Means sem PCA_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clusterização #\n",
    "\n",
    "file = open(\"Results/kmeansSemPCA.txt\", \"w\")\n",
    "scr_vector = []\n",
    "calinski_scr_vector =[]\n",
    "silhoette_scr_vector = []\n",
    "for x in range(2,201):\n",
    "    \n",
    "    km = KMeans(n_clusters=x, random_state=0, n_jobs=(-1)).fit(database)\n",
    "    scr = km.score(database)\n",
    "    calinski_scr = metrics.calinski_harabaz_score(database, km.labels_)\n",
    "    silhoette_scr = metrics.silhouette_score(database, km.labels_ , metric='euclidean',sample_size=8000)\n",
    "    \n",
    "    scr_vector.append(scr)\n",
    "    calinski_scr_vector.append(calinski_scr)\n",
    "    silhoette_scr_vector.append(silhoette_scr)\n",
    "    print(str(scr), \"  \",str(calinski_scr), \"  \", str(silhoette_scr))\n",
    "    \n",
    "    file.write(\"Kmeans: N°: \"+ str(x) +\" - score= \"+ str(scr) +\" calinski= \"+ str(calinski_scr)+\" silhoette=\"+str(silhoette_scr)+\"\\n\")    \n",
    "    file.flush()\n",
    "\n",
    "file.write(\"\\n\\nscore: \" + str(scr_vector))\n",
    "file.write(\"\\n\\ncalinski: \" + str(calinski_scr_vector))\n",
    "file.write(\"\\n\\nsilhoette: \" + str(silhoette_scr_vector))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráficos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gráfico de score vs Nº cluster\n",
    "plt.plot(range(2,201), scr_vector)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Nº clusters')\n",
    "plt.title('K-Means score vs Nº cluster')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de calinski score vs Nº cluster\n",
    "plt.plot(range(2,201), calinski_scr_vector)\n",
    "plt.ylabel('calinski score')\n",
    "plt.xlabel('Nº clusters')\n",
    "plt.title('Calinski score vs Nº cluster')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de silhoette score vs Nº cluster\n",
    "plt.plot(range(2,201), silhoette_scr_vector)\n",
    "plt.ylabel('silhoette score')\n",
    "plt.xlabel('Nº clusters')\n",
    "plt.title('silhoette score vs Nº cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _B. K-Means com PCA_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Aplica PCA ##\n",
    "pca_db = applyPCA(0.85, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clusterização #\n",
    "\n",
    "file = open(\"Results/kmeansComPCA.txt\", \"w\")\n",
    "\n",
    "matrix_calinski_scr = matrix_scr = matrix_silhoette_scr = [[0]*199 for i in range(5)]\n",
    "pca_values = [0.85, 0.90, 0.93, 0.95, 0.97]\n",
    "for x in pca_values:\n",
    "    pca_db = applyPCA(x, database)\n",
    "    for y in range(2,201):\n",
    "        km = KMeans(n_clusters=y, random_state=0, n_jobs=(-1)).fit(pca_db)\n",
    "        scr = km.score(pca_db)\n",
    "        calinski_scr = metrics.calinski_harabaz_score(pca_db, km.labels_)\n",
    "        silhoette_scr = metrics.silhouette_score(pca_db, km.labels_ , metric='euclidean',sample_size=8000)\n",
    "        \n",
    "        matrix_scr[pca_values.index(x)][y-2] = scr\n",
    "        matrix_calinski_scr[pca_values.index(x)][y-2] = calinski_scr\n",
    "        matrix_silhoette_scr[pca_values.index(x)][y-2] = silhoette_scr\n",
    "        print(str(scr), \"  \",str(calinski_scr), \"  \", str(silhoette_scr))\n",
    "        \n",
    "        file.write(\"Kmeans: PCA:\"+ str(x) +\" N°:\"+ str(y)+\"  - score= \"+ str(scr) +\" calinski= \"+ str(calinski_scr)+\" silhoette=\"+str(silhoette_scr)+\"\\n\")    \n",
    "        file.flush()\n",
    " \n",
    "file.write(\"\\n\\nscore: \" + str(matrix_scr))\n",
    "file.write(\"\\n\\ncalinski: \" + str(matrix_calinski_scr))\n",
    "file.write(\"\\n\\nsilhoette: \" + str(matrix_silhoette_scr))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráficos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gráfico de score vs Nº cluster\n",
    "plt.plot(range(2,201), matrix_scr[0])\n",
    "plt.plot(range(2,201), matrix_scr[1])\n",
    "plt.plot(range(2,201), matrix_scr[2])\n",
    "plt.plot(range(2,201), matrix_scr[3])\n",
    "plt.plot(range(2,201), matrix_scr[4])\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Nº clusters')\n",
    "plt.legend(['PCA = 0.85', 'PCA = 0.90', 'PCA = 0.93', 'PCA = 0.95', 'PCA = 0.97' ], loc=4)\n",
    "plt.title('K-Means score vs Nº cluster')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de calinski score vs Nº cluster\n",
    "plt.plot(range(2,201), matrix_calinski_scr[0])\n",
    "plt.plot(range(2,201), matrix_calinski_scr[1])\n",
    "plt.plot(range(2,201), matrix_calinski_scr[2])\n",
    "plt.plot(range(2,201), matrix_calinski_scr[3])\n",
    "plt.plot(range(2,201), matrix_calinski_scr[4])\n",
    "plt.ylabel('calinski score')\n",
    "plt.xlabel('Nº clusters')\n",
    "plt.legend(['PCA = 0.85', 'PCA = 0.90', 'PCA = 0.93', 'PCA = 0.95', 'PCA = 0.97' ], loc=4)\n",
    "plt.title('Calinski score vs Nº cluster')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de silhoette score vs Nº cluster\n",
    "plt.plot(range(2,201), matrix_silhoette_scr[0])\n",
    "plt.plot(range(2,201), matrix_silhoette_scr[1])\n",
    "plt.plot(range(2,201), matrix_silhoette_scr[2])\n",
    "plt.plot(range(2,201), matrix_silhoette_scr[3])\n",
    "plt.plot(range(2,201), matrix_silhoette_scr[4])\n",
    "plt.ylabel('silhoette score')\n",
    "plt.xlabel('Nº clusters')\n",
    "plt.legend(['PCA = 0.85', 'PCA = 0.90', 'PCA = 0.93', 'PCA = 0.95', 'PCA = 0.97' ], loc=4)\n",
    "plt.title('silhoette score vs Nº cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _C. K-Means nas bases geradas_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"Results/kmeansCustomSet.txt\", \"w\")\n",
    "scr_vector = []\n",
    "calinski_scr_vector =[]\n",
    "silhoette_scr_vector = []\n",
    "for x in [47, 80]:\n",
    "    for y in [\"wn\", \"lanc\", \"snow\", \"porter\"]:\n",
    "        scr = trainCustomSets(getData(True, y), x) \n",
    "\n",
    "        scr_vector.append(scr)\n",
    "\n",
    "        file.write(\"Kmeans: N°: \"+ str(x) +\" - score= \"+ str(scr))\n",
    "        file.flush()\n",
    "\n",
    "file.write(\"\\n\\nscore: \" + str(scr_vector))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação das prováveis quantidade de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotclusters (km, clusters):\n",
    "    # Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "    h = .001 # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "    y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Obtain labels for each point in mesh. Use last trained model.\n",
    "    Z = km.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    plt.imshow(Z, interpolation='nearest',\n",
    "               extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "               cmap=plt.cm.Paired,\n",
    "               aspect='auto', origin='lower')\n",
    "\n",
    "    plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "    # Plot the centroids as a white X\n",
    "    centroids = km.cluster_centers_\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='.', s=10, linewidths=3,\n",
    "                color='w', zorder=10)\n",
    "    plt.title('K-means clustering with '+ str(clusters)+ ' clusters\\nCentroids are marked with white dots')\n",
    "    plt.xlim(x_min+0.85, x_max - 0.9)\n",
    "    plt.ylim(y_min+0.9, y_max - 0.85)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Função para obter os medoides e os pontos mais proximos aos medoids\n",
    "def getMedoid(allset, centroid):\n",
    "    mindist = float('inf')\n",
    "    allset = np.array(allset)\n",
    "    indice = 0\n",
    "    for i in allset:\n",
    "        curdist = cdist(np.atleast_2d(centroid), np.atleast_2d(i))[0][0]\n",
    "        if curdist < mindist and curdist != 0:\n",
    "            mindist = curdist\n",
    "            medoid = i\n",
    "            mindice = indice\n",
    "        indice = indice +1\n",
    "    return medoid, mindice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=47, random_state=0, n_jobs=(-1)).fit(database)\n",
    "km2 = KMeans(n_clusters=80, random_state=0, n_jobs=(-1)).fit(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"Results/Medoids47Clusters.txt\", \"w\")\n",
    "file2 = open(\"Results/MaisProximos47Clusters.txt\", \"w\")\n",
    "\n",
    "file2.write(\"medoid_id   closest_id\\n\")\n",
    "for x in km.cluster_centers_ :\n",
    "    medoid_position, medoid_id = getMedoid(database,x)\n",
    "    closest_position, closest_id = getMedoid(database,medoid_position)\n",
    "    file.write(str(medoid_position)+\"\\n\")\n",
    "    file2.write(str(medoid_id)+\" , \"+str(closest_id)+\"\\n\")\n",
    "\n",
    "file.close()\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"Results/Medoids80Clusters.txt\", \"w\")\n",
    "file2 = open(\"Results/MaisProximos80Clusters.txt\", \"w\")\n",
    "\n",
    "medoids = closest_text = medoids2 = closest_text2 = []\n",
    "for x in km2.cluster_centers_ :\n",
    "    currmedois, closest = getMedoid(database,x)\n",
    "    file.write(str(currmedois)+\"\\n\\n\")\n",
    "    file2.write(str(closest)+\"\\n\")\n",
    "\n",
    "file.close()\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Redução da dimensionalidade do vetor de variáveis e fit com a quantidade de clusters escolhida\n",
    "reduced_data = PCA(n_components=2).fit_transform(database)\n",
    "km = KMeans(n_clusters=47, random_state=0, n_jobs=(-1)).fit(reduced_data)\n",
    "km2 = KMeans(n_clusters=80, random_state=0, n_jobs=(-1)).fit(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot dos diagramas de Voronoi para 47 e 80 clusters\n",
    "plotclusters(km, 47)\n",
    "plotclusters(km2, 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
